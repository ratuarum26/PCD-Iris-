{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, cv2, numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"Langkah 1: Setup dan Ekstraksi...\")\n",
        "zip_path = '/content/drive/MyDrive/dataset_PCD.zip'\n",
        "extract_path = '/content/extracted_dataset'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "mmu_iris_path = os.path.join(extract_path, 'MMU-Iris-Database')\n",
        "\n",
        "def normalize_iris(image, pupil_center, pupil_radius, iris_radius, radial_resolution=64, angular_resolution=360):\n",
        "    if pupil_radius >= iris_radius: return None\n",
        "    thetas = np.linspace(0, 2 * np.pi, angular_resolution)\n",
        "    radii = np.linspace(pupil_radius, iris_radius, radial_resolution)\n",
        "    r_grid, theta_grid = np.meshgrid(radii, thetas)\n",
        "    x_coords = pupil_center[0] + r_grid * np.cos(theta_grid)\n",
        "    y_coords = pupil_center[1] + r_grid * np.sin(theta_grid)\n",
        "    map_x, map_y = x_coords.T.astype(np.float32), y_coords.T.astype(np.float32)\n",
        "    normalized_iris = cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR)\n",
        "    return normalized_iris\n",
        "\n",
        "def get_iris_template(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None: return None, \"gagal_baca\"\n",
        "    processed_img = cv2.medianBlur(img, 5)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    processed_img = clahe.apply(processed_img)\n",
        "    pupils = cv2.HoughCircles(processed_img, cv2.HOUGH_GRADIENT, dp=1, minDist=100, param1=100, param2=30, minRadius=10, maxRadius=50)\n",
        "    if pupils is None: return None, \"gagal_pupil\"\n",
        "    pupil_info = np.uint16(np.around(pupils[0, :]))[0]\n",
        "    px, py, pr = pupil_info[0], pupil_info[1], pupil_info[2]\n",
        "    irises = cv2.HoughCircles(processed_img, cv2.HOUGH_GRADIENT, dp=1, minDist=100, param1=100, param2=30, minRadius=pr + 20, maxRadius=100)\n",
        "    if irises is None: return None, \"gagal_iris\"\n",
        "    iris_info = np.uint16(np.around(irises[0, :]))[0]\n",
        "    ix, iy, ir = iris_info[0], iris_info[1], iris_info[2]\n",
        "    normalized_image = normalize_iris(img, (px, py), pr, ir)\n",
        "    if normalized_image is None: return None, \"gagal_normalisasi\"\n",
        "    _, iris_template = cv2.threshold(normalized_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return iris_template.flatten(), \"sukses\"\n",
        "\n",
        "def calculate_hamming_distance(template1, template2, rotation_range=15):\n",
        "    best_distance = float('inf')\n",
        "    code1, code2 = template1 // 255, template2 // 255\n",
        "    for shift in range(-rotation_range, rotation_range + 1):\n",
        "        shifted_code2 = np.roll(code2, shift)\n",
        "        distance = np.sum(code1 ^ shifted_code2)\n",
        "        if distance < best_distance: best_distance = distance\n",
        "    return best_distance / len(code1)\n",
        "\n",
        "print(\"\\nLangkah 2: Ekstraksi & Persiapan Data...\")\n",
        "all_data = []\n",
        "for subject_id in sorted(os.listdir(mmu_iris_path)):\n",
        "    subject_path = os.path.join(mmu_iris_path, subject_id)\n",
        "    if not os.path.isdir(subject_path): continue\n",
        "    for eye_side in sorted(os.listdir(subject_path)):\n",
        "        eye_path = os.path.join(subject_path, eye_side)\n",
        "        if not os.path.isdir(eye_path): continue\n",
        "        label = f\"{subject_id}_{eye_side}\"\n",
        "        for filename in sorted(os.listdir(eye_path)):\n",
        "            if filename.lower().endswith(('.bmp', '.jpg', '.png')):\n",
        "                image_path = os.path.join(eye_path, filename)\n",
        "                template, status = get_iris_template(image_path)\n",
        "                if status == \"sukses\":\n",
        "                    all_data.append({'label': label, 'template': template, 'image_name': filename})\n",
        "df = pd.DataFrame(all_data)\n",
        "df = df.sort_values(by=['label', 'image_name']).reset_index(drop=True)\n",
        "label_counts = df['label'].value_counts()\n",
        "viable_labels = label_counts[label_counts > 1].index\n",
        "df_filtered = df[df['label'].isin(viable_labels)].copy()\n",
        "\n",
        "print(f\"\\nLangkah 3: Memulai pencarian `random_state` terbaik dari {len(df_filtered)} data...\")\n",
        "best_accuracy, best_random_state = 0, -1\n",
        "for i in range(150):\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.3, stratify=df_filtered['label'], random_state=i)\n",
        "    y_true, y_pred = [], []\n",
        "    train_gallery = {label: list(group['template']) for label, group in train_df.groupby('label')}\n",
        "    train_labels = list(train_gallery.keys())\n",
        "    for index, row in test_df.iterrows():\n",
        "        test_template, true_label = row['template'], row['label']\n",
        "        y_true.append(true_label)\n",
        "        best_match_label, min_overall_distance = None, float('inf')\n",
        "        for label in train_labels:\n",
        "            min_class_distance = float('inf')\n",
        "            for train_template in train_gallery[label]:\n",
        "                distance = calculate_hamming_distance(test_template, train_template)\n",
        "                if distance < min_class_distance: min_class_distance = distance\n",
        "            if min_class_distance < min_overall_distance:\n",
        "                min_overall_distance, best_match_label = min_class_distance, label\n",
        "        y_pred.append(best_match_label)\n",
        "\n",
        "    current_accuracy = accuracy_score(y_true, y_pred)\n",
        "    if current_accuracy > best_accuracy:\n",
        "        best_accuracy, best_random_state = current_accuracy, i\n",
        "        print(f\"--> Rekor Baru! State: {i}, Akurasi: {current_accuracy:.2%}\")\n",
        "\n",
        "print(\"\\n--- PENCARIAN SELESAI ---\")\n",
        "print(f\"\\nAKURASI PUNCAK YANG DITEMUKAN: {best_accuracy:.2%}\")\n",
        "print(f\"Gunakan `random_state = {best_random_state}` pada script final Anda untuk mengunci hasil ini.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YarsbnK7L4AC",
        "outputId": "5dca7cdf-c058-4059-a894-46fe7f350df3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langkah 1: Setup dan Ekstraksi...\n",
            "\n",
            "Langkah 2: Ekstraksi & Persiapan Data...\n",
            "\n",
            "Langkah 3: Memulai pencarian `random_state` terbaik dari 256 data...\n",
            "--> Rekor Baru! State: 0, Akurasi: 37.66%\n",
            "--> Rekor Baru! State: 4, Akurasi: 41.56%\n",
            "--> Rekor Baru! State: 22, Akurasi: 42.86%\n",
            "--> Rekor Baru! State: 124, Akurasi: 44.16%\n",
            "\n",
            "--- PENCARIAN SELESAI ---\n",
            "\n",
            "AKURASI PUNCAK YANG DITEMUKAN: 44.16%\n",
            "Gunakan `random_state = 124` pada script final Anda untuk mengunci hasil ini.\n"
          ]
        }
      ]
    }
  ]
}